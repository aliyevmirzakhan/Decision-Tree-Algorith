{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"C:\\\\Users\\\\Mirzakhan Aliyev\\\\Desktop\\\\DT.csv\",index_col = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Data Seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split (Data, test_size):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size*len(Data))\n",
    "    indices = Data.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k = test_size)\n",
    "    \n",
    "    test_Data = Data.loc[test_indices]\n",
    "    train_Data = Data.drop(test_indices)\n",
    "    \n",
    "    return train_Data, test_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the Helper functions for Tree Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day   Outlook Humidity    Wind Play\n",
       "0  D1     Sunny     High    Weak   No\n",
       "1  D2     Sunny     High  Strong   No\n",
       "2  D3  Overcast     High    Weak  Yes\n",
       "3  D4      Rain     High    Weak  Yes\n",
       "4  D5      Rain   Normal    Weak  Yes"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "train_Data, test_Data = train_test_split(Data, 1)\n",
    "train_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_Data.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking The Purity of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity (data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    # This function Takes Data Frame up with a condition given during input, and accordingly \n",
    "    # Calculates the label_colum unique values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify_Data (data):\n",
    "    label_column = data[:,-1]\n",
    "    unique_classes, counts_unique_classes = np.unique (label_column, return_counts = True)\n",
    "    index = counts_unique_classes.argmax()\n",
    "    \n",
    "    classification = unique_classes[index]\n",
    "    return classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classify_Data(train_Data[train_Data['Outlook']=='Rain'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Potential_Splits (data):\n",
    "    Potential_Splits = {}\n",
    "\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range (n_columns - 1):\n",
    "            Potential_Splits[column_index] = [] #This empty list to be filled up\n",
    "            values = data[:, column_index]\n",
    "            unique_values = np.unique(values)\n",
    "            type_of_feature = FEATURE_TYPES[column_index]\n",
    "            \n",
    "            Potential_Splits[column_index] = [] #This empty list to be filled up\n",
    "            \n",
    "            if type_of_feature == \"continuous\":\n",
    "                for index in range(len(unique_values)):\n",
    "                    if index != 0:\n",
    "                        current_value = unique_values[index]\n",
    "                        previous_value = unique_values[index - 1]\n",
    "                        Potential_split = (current_value + previous_value)/2\n",
    "                        Potential_Splits[column_index].append(Potential_split)\n",
    "            else:\n",
    "                \n",
    "                Potential_Splits[column_index] = unique_values\n",
    "\n",
    "    return Potential_Splits\n",
    "\n",
    "#  This Function checks the possible splitting options within each columns, can be used both for continuous and categorical \n",
    "#  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array(['D1', 'D10', 'D11', 'D12', 'D13', 'D15', 'D2', 'D3', 'D4', 'D5',\n",
       "        'D6', 'D7', 'D8', 'D9'], dtype=object),\n",
       " 1: array(['Overcast', 'Rain', 'Sunny'], dtype=object),\n",
       " 2: array(['High', 'Normal'], dtype=object),\n",
       " 3: array(['Strong', 'Weak'], dtype=object)}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Get_Potential_Splits(train_Data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data Function to be used in Entropy identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data (data, split_column, split_value):\n",
    "    split_column_values = data[:,split_column]\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    \n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >= split_value]\n",
    "    else:\n",
    "        \n",
    "        #For Categorical Data we have only categories that can be splitted\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380423950607804"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_below, data_above = split_data(data, 3, 'Weak')\n",
    "calculate_overall_entropy(data_below, data_above)\n",
    "#data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest Overall Entropy Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy (data):\n",
    "    label_column = data[:,-1]\n",
    "    _, counts = np.unique(label_column, return_counts = True)\n",
    "    summ = counts.sum()\n",
    "    probability = counts/summ\n",
    "    entropy = sum (probability * (-np.log2(probability)))\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy (data_below, data_above):\n",
    "    n_datapoints = len(data_below) + len(data_above)\n",
    "\n",
    "    p_data_below = len(data_below)/n_datapoints\n",
    "    p_data_above = len(data_above)/n_datapoints\n",
    "\n",
    "    overall_entropy = p_data_below*calculate_entropy(data_below) + p_data_above*calculate_entropy(data_above)\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split (data, Potential_Splits, columns_nottobe_splitted):\n",
    "    overall_entropy = 999\n",
    "    nsc = columns_nottobe_splitted\n",
    "    \n",
    "    for column_index in Potential_Splits:\n",
    "        if column_index != nsc:\n",
    "            for value in Potential_Splits[column_index]:\n",
    "                data_below, data_above = split_data(data, split_column = column_index, split_value = value)\n",
    "                current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "                if current_overall_entropy <= overall_entropy:\n",
    "                    overall_entropy = current_overall_entropy\n",
    "                    best_split_column = column_index\n",
    "                    best_split_value  = value\n",
    "                    data_below, data_above = split_data(data, split_column = column_index, split_value = value)\n",
    "                    current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "                \n",
    "\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the type of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_typeof_thefeature (Data):\n",
    "    feature_types = []\n",
    "    unique_value_treshold = 15\n",
    "    \n",
    "    for column in Data.columns:\n",
    "        unique_values = Data[column].unique()\n",
    "        example_value = Data[column][0]\n",
    "        \n",
    "        if (len(unique_values) <= unique_value_treshold) or (isinstance(example_value, str)):\n",
    "            feature_types.append(\"categorical\")\n",
    "        else:\n",
    "            feature_types.append(\"continuous\")\n",
    "            \n",
    "            \n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day  -  categorical\n",
      "Outlook  -  categorical\n",
      "Humidity   -  categorical\n",
      "Wind  -  categorical\n",
      "Label  -  categorical\n"
     ]
    }
   ],
   "source": [
    "feature_type = determine_typeof_thefeature(Data)\n",
    "i = 0\n",
    "for column in Data.columns:\n",
    "    print(column, \" - \", feature_type[i])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation of Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(Data, counter = 0, min_samples = 2, max_depth = 5):\n",
    "    \n",
    "    # We inted to input DataFrame in the first call, but since the function will be multiple called\n",
    "    # The helper function will use the data as numpy array, and output array as well.\n",
    "    # So we first switch the DataFrame to Array, but for the next calls the input df will be array, that's we \n",
    "    # leave it as it is.\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = Data.columns\n",
    "        FEATURE_TYPES = determine_typeof_thefeature(Data) # Since This variable is GLOBAL we can use it any code block also\n",
    "        data = Data.values\n",
    "    else:\n",
    "        data = Data\n",
    "    \n",
    "    \n",
    "    # Base Case\n",
    "    # The samples are the colum size or the features, and if it does not pass certain treshold, we just choose most frequent\n",
    "    # max_depth is just the number of layer that we want the subtree to extend\n",
    "    if check_purity(data) or len(data)<min_samples or (counter == max_depth):\n",
    "        classification = Classify_Data(data)\n",
    "        return classification\n",
    "    # Recursive Case \n",
    "    else:\n",
    "        counter +=1\n",
    "        \n",
    "        # Calling the Helper Functions\n",
    "        potential_splits = Get_Potential_Splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits, 0)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # Instantiate the sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \" {} <= {} \".format(feature_name, split_value)\n",
    "        else:\n",
    "            question = \" {} = {} \".format(feature_name, split_value)\n",
    "        sub_tree = {question: []}\n",
    "        #Define the answers\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Outlook = Overcast ': ['Yes',\n",
      "                          {' Humidity = Normal ': [{' Wind = Weak ': ['Yes',\n",
      "                                                                      {' Outlook = Sunny ': ['Yes',\n",
      "                                                                                             'No']}]},\n",
      "                                                   {' Outlook = Sunny ': ['No',\n",
      "                                                                          {' Wind = Weak ': ['Yes',\n",
      "                                                                                             'No']}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(Data)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example (example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "    if comparison_operator == \"<=\":\n",
    "\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    else:\n",
    "        \n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    #Base Case\n",
    "\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D14</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Day Outlook Humidity    Wind Play\n",
       "13  D14    Rain     High  Strong   No"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = test_Data\n",
    "#example\n",
    "\n",
    "tree = decision_tree_algorithm(Data)\n",
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accurac (Data, tree):\n",
    "    Data['Classification'] = Data.apply(classify_example, axis = 1, args=(tree,))\n",
    "    Data['Classification_Correctness'] = Data.Label == Data.Classification\n",
    "    \n",
    "    accuracy = Data.Classification_Correctness.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorical', 'categorical', 'categorical', 'categorical', 'categorical']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_TYPES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
